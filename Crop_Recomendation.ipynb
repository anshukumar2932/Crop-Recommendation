{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1760012,
          "sourceType": "datasetVersion",
          "datasetId": 1046158
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Crop-Recomendation",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshukumar2932/Crop-Recommendation/blob/main/Crop_Recomendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "atharvaingle_crop_recommendation_dataset_path = kagglehub.dataset_download('atharvaingle/crop-recommendation-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "lab-G-rKvmfV"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#importing all neccesary modules"
      ],
      "metadata": {
        "id": "rVTurysCvmfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.feature_selection import RFE, mutual_info_classif\n",
        "from sklearn.inspection import permutation_importance\n",
        "from xgboost import XGBClassifier  # Added import for XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import sparse"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:12.443376Z",
          "iopub.execute_input": "2025-08-29T06:42:12.443703Z",
          "iopub.status.idle": "2025-08-29T06:42:12.450461Z",
          "shell.execute_reply.started": "2025-08-29T06:42:12.44368Z",
          "shell.execute_reply": "2025-08-29T06:42:12.449357Z"
        },
        "id": "ba7rDhvuvmfX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set random seed for reproducibility"
      ],
      "metadata": {
        "id": "WKJ8kLw4vmfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:12.45341Z",
          "iopub.execute_input": "2025-08-29T06:42:12.45368Z",
          "iopub.status.idle": "2025-08-29T06:42:12.46876Z",
          "shell.execute_reply.started": "2025-08-29T06:42:12.453659Z",
          "shell.execute_reply": "2025-08-29T06:42:12.467706Z"
        },
        "id": "VAerMQ3vvmfX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "y9fu94MGvmfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List input files\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "data = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:12.470245Z",
          "iopub.execute_input": "2025-08-29T06:42:12.470529Z",
          "iopub.status.idle": "2025-08-29T06:42:12.493833Z",
          "shell.execute_reply.started": "2025-08-29T06:42:12.470507Z",
          "shell.execute_reply": "2025-08-29T06:42:12.492939Z"
        },
        "id": "8qqs0IsKvmfX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print detailed dataset information"
      ],
      "metadata": {
        "id": "sq9r_-KLvmfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDataset Shape:\", data.shape)\n",
        "print(\"\\nFeature Descriptions:\")\n",
        "print(\"- N: Nitrogen content in soil (kg/ha)\")\n",
        "print(\"- P: Phosphorus content in soil (kg/ha)\")\n",
        "print(\"- K: Potassium content in soil (kg/ha)\")\n",
        "print(\"- temperature: Temperature in Celsius\")\n",
        "print(\"- humidity: Relative humidity in %\")\n",
        "print(\"- ph: Soil pH value\")\n",
        "print(\"- rainfall: Rainfall in mm\")\n",
        "print(\"- NPK: Average of Nitrogen, Phosphorus, and Potassium\")\n",
        "print(\"- THI: Temperature-Humidity Index (temperature * humidity / 100)\")\n",
        "print(\"- rainfall_level: Categorical rainfall (Low, Medium, High, Very High)\")\n",
        "print(\"- ph_category: Categorical pH (Acidic, Neutral, Alkaline)\")\n",
        "print(\"- temp_rain_interaction: Temperature * Rainfall interaction\")\n",
        "print(\"- ph_rain_interaction: pH * Rainfall interaction\")\n",
        "print(\"- soil_fertility_index: Weighted NPK ratio\")\n",
        "print(\"- season: Seasonal indicator (Winter, Spring, Summer, Monsoon)\")\n",
        "print(\"- N_P_ratio: Nitrogen to Phosphorus ratio\")\n",
        "print(\"- N_K_ratio: Nitrogen to Potassium ratio\")\n",
        "print(\"- log_rainfall: Log-transformed rainfall\")\n",
        "print(\"- N_times_P: Nitrogen * Phosphorus interaction\")\n",
        "print(\"- P_times_K: Phosphorus * Potassium interaction\")\n",
        "print(\"- N_times_K: Nitrogen * Potassium interaction\")\n",
        "print(\"- env_stress_index: Environmental stress index (temperature, humidity, pH)\")\n",
        "print(\"- rainfall_ph_interaction: Categorical rainfall * pH interaction\")\n",
        "print(\"- soil_moisture_proxy: Proxy for soil moisture (humidity * rainfall)\")\n",
        "print(\"- nutrient_balance_score: Deviation from optimal NPK ratio\")\n",
        "print(\"- temp_humidity_ratio: Temperature to humidity ratio\")\n",
        "print(\"- npk_variance: Variance of N, P, K\")\n",
        "print(\"- ph_temp_interaction: pH * Temperature interaction\")\n",
        "print(\"- nutrient_availability_index: Normalized nutrient levels\")\n",
        "print(\"\\nStatistical Summary of Numerical Features:\")\n",
        "print(data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']].describe())\n",
        "print(\"\\nClass Distribution (Crop Labels):\")\n",
        "print(data['label'].value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:12.49512Z",
          "iopub.execute_input": "2025-08-29T06:42:12.495399Z",
          "iopub.status.idle": "2025-08-29T06:42:12.522432Z",
          "shell.execute_reply.started": "2025-08-29T06:42:12.495367Z",
          "shell.execute_reply": "2025-08-29T06:42:12.521504Z"
        },
        "id": "aBydcNQQvmfX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "VPQoIGYQvmfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA: Top 5 rows\n",
        "print(\"\\nTop 5 rows of the dataset\")\n",
        "print(data.head())\n",
        "\n",
        "# EDA: Bottom 5 rows\n",
        "print(\"\\nBottom 5 rows of the dataset\")\n",
        "print(data.tail())\n",
        "\n",
        "# EDA: Dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(data.info())\n",
        "\n",
        "# EDA: Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# EDA: Check for duplicates\n",
        "print(\"\\nDuplicated Rows:\")\n",
        "print(data.duplicated().sum())\n",
        "\n",
        "# EDA: Unique labels\n",
        "print(\"\\nUnique Crop Labels:\")\n",
        "print(data['label'].unique())\n",
        "\n",
        "# EDA: Distribution of numerical features\n",
        "num_features = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(num_features, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.histplot(data[col], kde=True, bins=30)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# EDA: Correlation heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(data[num_features].corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap of Features\")\n",
        "plt.show()\n",
        "\n",
        "# EDA: Boxplots for outlier detection\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(num_features, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.boxplot(y=data[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# EDA: Average NPK values by crop\n",
        "plt.figure(figsize=(14, 6))\n",
        "avg_values = data.groupby(\"label\")[['N', 'P', 'K']].mean()\n",
        "avg_values.plot(kind=\"bar\")\n",
        "plt.title(\"Average NPK Values per Crop\")\n",
        "plt.ylabel(\"Mean Value\")\n",
        "plt.show()\n",
        "\n",
        "# EDA: Pairplot for sampled data\n",
        "sample_df = data.sample(500, random_state=42)\n",
        "sns.pairplot(sample_df, hue=\"label\", vars=['N', 'P', 'K', 'temperature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:12.523911Z",
          "iopub.execute_input": "2025-08-29T06:42:12.524532Z",
          "iopub.status.idle": "2025-08-29T06:42:25.356303Z",
          "shell.execute_reply.started": "2025-08-29T06:42:12.524508Z",
          "shell.execute_reply": "2025-08-29T06:42:25.35537Z"
        },
        "id": "V7bB-NOXvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering function"
      ],
      "metadata": {
        "id": "hcD-3M9-vmfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineer(data):\n",
        "    data['NPK'] = (data['N'] + data['P'] + data['K']) / 3\n",
        "    data['THI'] = data['temperature'] * data['humidity'] / 100\n",
        "    data['rainfall_level'] = pd.cut(data['rainfall'],\n",
        "                                    bins=[0, 50, 100, 200, 300],\n",
        "                                    labels=['Low', 'Medium', 'High', 'Very High'])\n",
        "    def ph_category(p):\n",
        "        if p < 5.5:\n",
        "            return 'Acidic'\n",
        "        elif p <= 7.5:\n",
        "            return 'Neutral'\n",
        "        else:\n",
        "            return 'Alkaline'\n",
        "    data['ph_category'] = data['ph'].apply(ph_category)\n",
        "    data['temp_rain_interaction'] = data['temperature'] * data['rainfall']\n",
        "    data['ph_rain_interaction'] = data['ph'] * data['rainfall']\n",
        "    data['soil_fertility_index'] = 0.4 * data['N'] + 0.3 * data['P'] + 0.3 * data['K']\n",
        "    def get_season(t, r):\n",
        "        if t < 15 or r < 50:\n",
        "            return 'Winter'\n",
        "        elif 15 <= t < 25 and 50 <= r < 100:\n",
        "            return 'Spring'\n",
        "        elif t >= 25 and r < 150:\n",
        "            return 'Summer'\n",
        "        else:\n",
        "            return 'Monsoon'\n",
        "    data['season'] = data.apply(lambda x: get_season(x['temperature'], x['rainfall']), axis=1)\n",
        "    data['N_P_ratio'] = data['N'] / (data['P'] + 1e-6)\n",
        "    data['N_K_ratio'] = data['N'] / (data['K'] + 1e-6)\n",
        "    data['log_rainfall'] = np.log1p(data['rainfall'])\n",
        "    data['N_times_P'] = data['N'] * data['P']\n",
        "    data['P_times_K'] = data['P'] * data['K']\n",
        "    data['N_times_K'] = data['N'] * data['K']\n",
        "    data['env_stress_index'] = (data['temperature'] / 30 + data['humidity'] / 100 + (7 - data['ph']) / 7) / 3\n",
        "    data['rainfall_ph_interaction'] = data['rainfall_level'].astype(str) + '_' + data['ph_category'].astype(str)\n",
        "    data['soil_moisture_proxy'] = data['humidity'] * data['rainfall'] / 100\n",
        "    data['nutrient_balance_score'] = abs(data['N'] / 100 - data['P'] / 50 - data['K'] / 50)\n",
        "    data['temp_humidity_ratio'] = data['temperature'] / (data['humidity'] + 1e-6)\n",
        "    data['npk_variance'] = data[['N', 'P', 'K']].var(axis=1)\n",
        "    data['ph_temp_interaction'] = data['ph'] * data['temperature']\n",
        "    data['nutrient_availability_index'] = (data['N'] / 150 + data['P'] / 75 + data['K'] / 75) / 3\n",
        "    return data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:25.357649Z",
          "iopub.execute_input": "2025-08-29T06:42:25.357933Z",
          "iopub.status.idle": "2025-08-29T06:42:25.370574Z",
          "shell.execute_reply.started": "2025-08-29T06:42:25.357911Z",
          "shell.execute_reply": "2025-08-29T06:42:25.369766Z"
        },
        "id": "tHZnIZMBvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature engineering\n",
        "data = feature_engineer(data)\n",
        "print(\"\\nTop 5 rows after feature engineering:\")\n",
        "print(data.head())\n",
        "\n",
        "# Check for NaN/inf values (numeric columns only)\n",
        "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
        "print(\"\\nChecking for NaN values after feature engineering:\")\n",
        "print(data[numeric_columns].isna().sum())\n",
        "print(\"\\nRows with inf values:\")\n",
        "print(data[numeric_columns][np.isinf(data[numeric_columns]).any(axis=1)])\n",
        "data[numeric_columns] = data[numeric_columns].replace([np.inf, -np.inf], np.nan).fillna(data[numeric_columns].mean())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:25.371636Z",
          "iopub.execute_input": "2025-08-29T06:42:25.371911Z",
          "iopub.status.idle": "2025-08-29T06:42:25.461986Z",
          "shell.execute_reply.started": "2025-08-29T06:42:25.371891Z",
          "shell.execute_reply": "2025-08-29T06:42:25.461127Z"
        },
        "id": "pa_ryZjpvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables with separate LabelEncoders\n",
        "le_target = LabelEncoder()\n",
        "le_rainfall = LabelEncoder()\n",
        "le_ph = LabelEncoder()\n",
        "le_season = LabelEncoder()\n",
        "le_rainfall_ph = LabelEncoder()\n",
        "data['label'] = le_target.fit_transform(data['label'])\n",
        "data['rainfall_level'] = le_rainfall.fit_transform(data['rainfall_level'])\n",
        "data['ph_category'] = le_ph.fit_transform(data['ph_category'])\n",
        "data['season'] = le_season.fit_transform(data['season'])\n",
        "data['rainfall_ph_interaction'] = le_rainfall_ph.fit_transform(data['rainfall_ph_interaction'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:25.463861Z",
          "iopub.execute_input": "2025-08-29T06:42:25.464221Z",
          "iopub.status.idle": "2025-08-29T06:42:25.47332Z",
          "shell.execute_reply.started": "2025-08-29T06:42:25.4642Z",
          "shell.execute_reply": "2025-08-29T06:42:25.472489Z"
        },
        "id": "JalQaTjMvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle outliers by clipping\n",
        "for col in numeric_columns:\n",
        "    data[col] = np.clip(data[col], data[col].quantile(0.01), data[col].quantile(0.99))\n",
        "\n",
        "# Ensure original features are preserved for polynomial transformation\n",
        "X = data.drop('label', axis=1)\n",
        "core_features = ['N', 'P', 'K', 'temperature']\n",
        "# Add polynomial features (sparse for efficiency)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
        "X_poly = sparse.csr_matrix(poly.fit_transform(X[core_features]))\n",
        "poly_feature_names = poly.get_feature_names_out(core_features)\n",
        "X_poly_df = pd.DataFrame.sparse.from_spmatrix(X_poly, columns=poly_feature_names, index=X.index)\n",
        "X = pd.concat([X.drop(core_features, axis=1), X_poly_df], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:25.474186Z",
          "iopub.execute_input": "2025-08-29T06:42:25.474478Z",
          "iopub.status.idle": "2025-08-29T06:42:25.549867Z",
          "shell.execute_reply.started": "2025-08-29T06:42:25.474452Z",
          "shell.execute_reply": "2025-08-29T06:42:25.549132Z"
        },
        "id": "58l5cpOEvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation-based feature selection (exclude core polynomial features)\n",
        "numerical_features = [col for col in X.columns if col not in ['rainfall_level', 'ph_category', 'season', 'rainfall_ph_interaction']]\n",
        "corr_matrix = X[numerical_features].corr().abs().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = []\n",
        "for column in upper.columns:\n",
        "    correlated = upper[column][upper[column] > 0.8].index.tolist()\n",
        "    if correlated and column not in to_drop:\n",
        "        to_drop.append(correlated[0])\n",
        "if to_drop:\n",
        "    print(f\"\\nDropping high-correlation features: {to_drop}\")\n",
        "    X = X.drop(to_drop, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:42:25.550639Z",
          "iopub.execute_input": "2025-08-29T06:42:25.550892Z",
          "iopub.status.idle": "2025-08-29T06:42:25.578898Z",
          "shell.execute_reply.started": "2025-08-29T06:42:25.550872Z",
          "shell.execute_reply": "2025-08-29T06:42:25.578098Z"
        },
        "id": "NVUpGOtsvmfY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Mutual information-based feature selection\n",
        "mi_scores = mutual_info_classif(X, data['label'], random_state=42)\n",
        "mi_df = pd.DataFrame({'Feature': X.columns, 'MI Score': mi_scores})\n",
        "mi_df = mi_df.sort_values(by='MI Score', ascending=False)\n",
        "print(\"\\nMutual Information Scores:\")\n",
        "print(mi_df)\n",
        "# Select top 15 features based on MI scores\n",
        "selected_features = mi_df['Feature'].head(15).tolist()\n",
        "X = X[selected_features]\n",
        "\n",
        "# Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=8)\n",
        "X = X.loc[:, rfe.fit(X, data['label']).support_]\n",
        "print(\"\\nSelected Features after RFE:\", X.columns.tolist())\n",
        "\n",
        "# Split features and target\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Hyperparameter tuning for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 15],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "rfc = grid_search.best_estimator_\n",
        "print(\"\\nBest RandomForest Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train ensemble model with tuned weights\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "    ('rf', rfc), ('svm', svm), ('xgb', xgb)], voting='soft', weights=[0.5, 0.3, 0.2])\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Export model and preprocessing objects\n",
        "joblib.dump(ensemble, 'ensemble_model.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "joblib.dump(le_target, 'label_encoder_target.joblib')\n",
        "joblib.dump(le_rainfall, 'label_encoder_rainfall.joblib')\n",
        "joblib.dump(le_ph, 'label_encoder_ph.joblib')\n",
        "joblib.dump(le_season, 'label_encoder_season.joblib')\n",
        "joblib.dump(le_rainfall_ph, 'label_encoder_rainfall_ph.joblib')\n",
        "joblib.dump(poly, 'poly_transformer.joblib')\n",
        "joblib.dump(rfe, 'rfe_selector.joblib')\n",
        "print(\"\\nModel and preprocessing objects exported as 'ensemble_model.joblib', 'scaler.joblib', 'label_encoder_*.joblib', 'poly_transformer.joblib', 'rfe_selector.joblib'\")\n",
        "\n",
        "# Print model parameters and size\n",
        "print(\"\\nRandomForestClassifier Parameters:\")\n",
        "print(rfc.get_params())\n",
        "model_size = os.path.getsize('ensemble_model.joblib') / 1024  # Size in KB\n",
        "print(f\"\\nModel File Size: {model_size:.2f} KB\")\n",
        "\n",
        "# Evaluate ensemble model\n",
        "y_pred = ensemble.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "print(f'\\naccuracy score: {accuracy}')\n",
        "print(f'mean_squared_error: {mse}')\n",
        "print(f'classification report:\\n{class_report}')\n",
        "print(f'balanced accuracy score: {balanced_acc:.4f}')\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(ensemble, X, y, cv=5, scoring='accuracy')\n",
        "print(f'Cross-validation accuracy: {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}')\n",
        "\n",
        "# ROC-AUC score (one-vs-rest for multi-class)\n",
        "y_score = ensemble.predict_proba(X_test)\n",
        "roc_auc = roc_auc_score(y_test, y_score, multi_class='ovr')\n",
        "print(f\"\\nROC-AUC Score (One-vs-Rest): {roc_auc:.4f}\")\n",
        "\n",
        "# Permutation importance\n",
        "perm_importance = permutation_importance(rfc, X_test, y_test, n_repeats=10, random_state=42)\n",
        "print(\"\\nPermutation Importance:\")\n",
        "print(pd.DataFrame({'Feature': X.columns, 'Importance': perm_importance.importances_mean}))\n",
        "\n",
        "# Feature stability across CV folds\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "feature_importances = []\n",
        "for train_idx, _ in kf.split(X):\n",
        "    rfc.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
        "    feature_importances.append(rfc.feature_importances_)\n",
        "feature_stability = np.std(feature_importances, axis=0)\n",
        "print(\"\\nFeature Stability (Std Dev of Importances across CV Folds):\")\n",
        "print(pd.DataFrame({'Feature': X.columns, 'Importance Std': feature_stability}))\n",
        "\n",
        "# Visualize feature importance (for RandomForest)\n",
        "importances = rfc.feature_importances_\n",
        "feature_names = X.columns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title('Feature Importance - RandomForestClassifier')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix - Ensemble Model')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# Learning curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(rfc, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_scores.mean(axis=1), label='Training Score')\n",
        "plt.plot(train_sizes, test_scores.mean(axis=1), label='Validation Score')\n",
        "plt.xlabel('Training Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve - RandomForestClassifier')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Error analysis\n",
        "errors = pd.DataFrame(X_test[y_test != y_pred], columns=feature_names)\n",
        "errors['true_label'] = le_target.inverse_transform(y_test[y_test != y_pred])\n",
        "errors['predicted_label'] = le_target.inverse_transform(y_pred[y_test != y_pred])\n",
        "print(\"\\nMisclassified Instances (Sample):\")\n",
        "print(errors.head())\n",
        "\n",
        "# Function to predict crop for real-world input with validation\n",
        "def predict_crop(new_data, model, scaler, le_target, le_rainfall, le_ph, le_season, le_rainfall_ph, poly_transformer, rfe_selector):\n",
        "    required_columns = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
        "    if not all(col in new_data.columns for col in required_columns):\n",
        "        raise ValueError(f\"Input data must contain columns: {required_columns}\")\n",
        "    for col, (min_val, max_val) in {'N': (0, 200), 'P': (0, 200), 'K': (0, 200),\n",
        "                                    'temperature': (0, 50), 'humidity': (0, 100),\n",
        "                                    'ph': (0, 14), 'rainfall': (0, 500)}.items():\n",
        "        if (new_data[col] < min_val).any() or (new_data[col] > max_val).any():\n",
        "            raise ValueError(f\"{col} values must be between {min_val} and {max_val}\")\n",
        "    new_data = feature_engineer(new_data)\n",
        "    new_data = new_data.drop('label', axis=1, errors='ignore')\n",
        "    # Use fitted encoders instead of re-fitting\n",
        "    try:\n",
        "        new_data['rainfall_level'] = le_rainfall.transform(new_data['rainfall_level'])\n",
        "    except ValueError:\n",
        "        new_data['rainfall_level'] = le_rainfall.fit_transform(new_data['rainfall_level'])\n",
        "    try:\n",
        "        new_data['ph_category'] = le_ph.transform(new_data['ph_category'])\n",
        "    except ValueError:\n",
        "        new_data['ph_category'] = le_ph.fit_transform(new_data['ph_category'])\n",
        "    try:\n",
        "        new_data['season'] = le_season.transform(new_data['season'])\n",
        "    except ValueError:\n",
        "        new_data['season'] = le_season.fit_transform(new_data['season'])\n",
        "    try:\n",
        "        new_data['rainfall_ph_interaction'] = le_rainfall_ph.transform(new_data['rainfall_ph_interaction'])\n",
        "    except ValueError:\n",
        "        new_data['rainfall_ph_interaction'] = le_rainfall_ph.fit_transform(new_data['rainfall_ph_interaction'])\n",
        "    new_data[numeric_columns] = new_data[numeric_columns].replace([np.inf, -np.inf], np.nan).fillna(new_data[numeric_columns].mean())\n",
        "    new_data_poly = sparse.csr_matrix(poly_transformer.transform(new_data[core_features]))\n",
        "    new_data_poly_df = pd.DataFrame.sparse.from_spmatrix(new_data_poly, columns=poly_transformer.get_feature_names_out(core_features), index=new_data.index)\n",
        "    new_data = pd.concat([new_data.drop(core_features, axis=1), new_data_poly_df], axis=1)\n",
        "    if to_drop:\n",
        "        new_data = new_data.drop([col for col in to_drop if col in new_data.columns], axis=1)\n",
        "    # Ensure feature consistency\n",
        "    missing_cols = [col for col in selected_features if col not in new_data.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing features in new data: {missing_cols}\")\n",
        "    new_data = new_data[selected_features]\n",
        "    new_data = new_data.loc[:, rfe_selector.support_]\n",
        "    new_data_scaled = scaler.transform(new_data)\n",
        "    prediction = model.predict(new_data_scaled)\n",
        "    confidence = model.predict_proba(new_data_scaled)\n",
        "    predicted_crop = le_target.inverse_transform(prediction)\n",
        "    return predicted_crop, np.max(confidence, axis=1)\n",
        "\n",
        "# Simulate real-world input\n",
        "real_world_data = pd.DataFrame({\n",
        "    'N': [80, 90, 70], 'P': [40, 50, 45], 'K': [40, 45, 50],\n",
        "    'temperature': [25, 20, 30], 'humidity': [80, 70, 85],\n",
        "    'ph': [6.5, 6.0, 7.0], 'rainfall': [150, 100, 200]\n",
        "})\n",
        "predicted_crop, confidence = predict_crop(real_world_data, ensemble, scaler, le_target, le_rainfall, le_ph, le_season, le_rainfall_ph, poly, rfe)\n",
        "print(\"\\nReal-World Predictions:\")\n",
        "for i, (crop, conf) in enumerate(zip(predicted_crop, confidence)):\n",
        "    print(f\"Input {i+1}: Crop = {crop}, Confidence = {conf:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-29T06:43:29.087561Z",
          "iopub.execute_input": "2025-08-29T06:43:29.087877Z",
          "iopub.status.idle": "2025-08-29T06:45:53.914521Z",
          "shell.execute_reply.started": "2025-08-29T06:43:29.087854Z",
          "shell.execute_reply": "2025-08-29T06:45:53.912527Z"
        },
        "id": "9gQnfGG2vmfY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}